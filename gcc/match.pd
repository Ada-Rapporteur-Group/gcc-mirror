/* Match-and-simplify patterns for shared GENERIC and GIMPLE folding.
   This file is consumed by genmatch which produces gimple-match.c
   from it.

   Copyright (C) 2014 Free Software Foundation, Inc.
   Contributed by Richard Biener <rguenther@suse.de>

This file is part of GCC.

GCC is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free
Software Foundation; either version 3, or (at your option) any later
version.

GCC is distributed in the hope that it will be useful, but WITHOUT ANY
WARRANTY; without even the implied warranty of MERCHANTABILITY or
FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
for more details.

You should have received a copy of the GNU General Public License
along with GCC; see the file COPYING3.  If not see
<http://www.gnu.org/licenses/>.  */

/* tree-ssa/ifc-pr44710.c requires a < b ? c : d to fold to 1.
   ???  probably runs into issue of recursive folding of a < b op0.  */
/* tree-ssa/ssa-ccp-16.c wants to fold "hello"[i_2] to 0
   (fold_const_aggregate_ref_1).  */
/* tree-ssa/ssa-ccp-19.c wants to fold &a1_3->i to &MEM[(void *)&a]
   (get_addr_base_and_unit_offset_1). */
/* tree-ssa/ssa-ccp-22.c wants to fold b_2(D) <= t_1 to 1.
   We are missing compare constant folding to type boundaries.  */

/* The following is simplification done by gimple_fold_stmt_to_constant_1
   to aid propagation engines, producing is_gimple_min_invariants from
   invariant_addr + cst.  It may not be generally wanted
   (builtin-object-size) and thus may want to be restricted to 'simple'
   forms like &mem-ref or &decl.  */
/* Disable for GENERIC, this causes endless recursions of addr-expr
   expansion which folds a POINTER_PLUS_EXPR and doesn't expect
   an ADDR_EXPR in return.  */
#if GIMPLE
(match_and_simplify
  (pointer_plus (addr@2 @0) INTEGER_CST_P@1)
  (if (is_gimple_min_invariant (@2)))
  {
    HOST_WIDE_INT off;
    tree base = get_addr_base_and_unit_offset (@0, &off);
    off += tree_to_uhwi (@1);
    /* Now with that we should be able to simply write
       (addr (mem_ref (addr @base) (plus @off @1)))  */
    build1 (ADDR_EXPR, type,
            build2 (MEM_REF, TREE_TYPE (TREE_TYPE (@2)),
	    	    build_fold_addr_expr (base),
	            build_int_cst (ptr_type_node, off)));
  })
#endif



/* Patterns required to avoid SCCVN testsuite regressions.  */

/* (x >> 31) & 1 -> (x >> 31).  Folding in fold-const is more
   complicated here, it does
     Fold (X << C1) & C2 into (X << C1) & (C2 | ((1 << C1) - 1))
     (X >> C1) & C2 into (X >> C1) & (C2 | ~((type) -1 >> C1))
     if the new mask might be further optimized.  */
(match_and_simplify
  (bit_and (rshift@0 @1 INTEGER_CST_P@2) integer_onep)
  (if (compare_tree_int (@2, TYPE_PRECISION (TREE_TYPE (@1)) - 1) == 0))
  @0)

/* COMPLEX_EXPR and REALPART/IMAGPART_EXPR cancellations.  */
(match_and_simplify
  (complex (realpart @0) (imagpart @0))
  @0)
(match_and_simplify
  (realpart (complex @0 @1))
  @0)
(match_and_simplify
  (imagpart (complex @0 @1))
  @1)

/* One unary pattern.  */

/* fold_negate_exprs convert - (~A) to A + 1.  */
(match_and_simplify
  (negate (bit_not integral_op_p@0))
  (plus @0 { build_int_cst (TREE_TYPE (@0), 1); } ))

/* One ternary pattern.  */

/* Due to COND_EXPRs weirdness in GIMPLE the following won't work
   without some hacks in the code generator.  */
(match_and_simplify
  (cond (bit_not @0) @1 @2)
  (cond @0 @2 @1))

/* match-and-simplify handles constant folding so we
   can just do the decomposition here.  */
(match_and_simplify
  (fma INTEGER_CST_P@0 INTEGER_CST_P@1 @3)
  (plus (mult @0 @1) @3))

#include "match-plusminus.pd"
#include "match-bitwise.pd"
#include "match-rotate.pd"
#include "match-builtin.pd"
#include "match-constant-folding.pd"

/* ????s

   We cannot reasonably match vector CONSTRUCTORs or vector constants
   without using special predicates.  Nor can we reasonably generate
   variable-length stuff with pattern expressions.

 */
