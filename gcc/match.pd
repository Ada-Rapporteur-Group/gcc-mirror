/* Match-and-simplify patterns for shared GENERIC and GIMPLE folding.
   This file is consumed by genmatch which produces gimple-match.c
   and generic-match.c from it.

   Copyright (C) 2014 Free Software Foundation, Inc.
   Contributed by Richard Biener <rguenther@suse.de>
   and Prathamesh Kulkarni  <bilbotheelffriend@gmail.com>

This file is part of GCC.

GCC is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free
Software Foundation; either version 3, or (at your option) any later
version.

GCC is distributed in the hope that it will be useful, but WITHOUT ANY
WARRANTY; without even the implied warranty of MERCHANTABILITY or
FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
for more details.

You should have received a copy of the GNU General Public License
along with GCC; see the file COPYING3.  If not see
<http://www.gnu.org/licenses/>.  */


/* Generic tree predicates we inherit.  */
(define_predicates
   integer_onep integer_zerop integer_all_onesp
   real_zerop real_onep
   CONSTANT_CLASS_P)


/* Simplifications of operations with one constant operand and
   simplifications to constants.  */

(for op (plus pointer_plus minus bit_ior bit_xor)
  (simplify
    (op @0 integer_zerop)
    (non_lvalue @0)))

/* Simplify x - x.
   This is unsafe for certain floats even in non-IEEE formats.
   In IEEE, it is unsafe because it does wrong for NaNs.
   Also note that operand_equal_p is always false if an operand
   is volatile.  */
(simplify
  (minus @0 @0)
  (if (!FLOAT_TYPE_P (type) || !HONOR_NANS (TYPE_MODE (type)))
   { build_zero_cst (type); }))

(simplify
  (mult @0 integer_zerop@1)
  @1)

/* Make sure to preserve divisions by zero.  This is the reason why
   we don't simplify x / x to 1 or 0 / x to 0.  */
(for op (mult trunc_div ceil_div floor_div round_div exact_div)
  (simplify
    (op @0 integer_onep)
    (non_lvalue @0)))

/* Same applies to modulo operations, but fold is inconsistent here
   and simplifies 0 % x to 0, only preserving literal 0 % 0.  */
(for op (ceil_mod floor_mod round_mod trunc_mod)
 /* 0 % X is always zero.  */
 (simplify
  (op integer_zerop@0 @1)
  /* But not for 0 % 0 so that we can get the proper warnings and errors.  */
  (if (!integer_zerop (@1))
   @0))
 /* X % 1 is always zero.  */
 (simplify
  (op @0 integer_onep)
  { build_zero_cst (type); }))

/* x | ~0 -> ~0  */
(simplify
  (bit_ior @0 integer_all_onesp@1)
  @1)

/* x & 0 -> 0  */
(simplify
  (bit_and @0 integer_zerop@1)
  @1)

/* x ^ x -> 0 */
(simplify
  (bit_xor @0 @0)
  { build_zero_cst (type); })





/* Simple example for a user-defined predicate - modeled after
   fold-const.c:negate_expr_p.  */
(match negate_expr_p
 INTEGER_CST
 (if (TYPE_OVERFLOW_WRAPS (type)
      || may_negate_without_overflow_p (t))))
(match negate_expr_p
 (bit_not @0)
 (if (INTEGRAL_TYPE_P (type) && TYPE_OVERFLOW_WRAPS (type))))
(match negate_expr_p
 FIXED_CST)
(match negate_expr_p
 (negate @0))
(match negate_expr_p
 REAL_CST
 (if (REAL_VALUE_NEGATIVE (TREE_REAL_CST (t)))))
/* ???  For VECTOR_CST and COMPLEX_CST we don't have an easy way
   to express the recursion (in the match pattern).  Recursing
   in the if expression causes us to refer to the fold-const.c:negate_expr_p
   predicate as predicates are not "replaced" (mangled) in c-exprs.  */
(match negate_expr_p
 /* -(A + B) -> (-A) - B.  */
 /* -(A + B) -> (-B) - A.  */
 (plus:c negate_expr_p @0)
 (if (!HONOR_SIGN_DEPENDENT_ROUNDING (TYPE_MODE (type))
      && !HONOR_SIGNED_ZEROS (TYPE_MODE (type)))))
(match negate_expr_p
  (minus @0 @1)
  (if (!HONOR_SIGN_DEPENDENT_ROUNDING (TYPE_MODE (type))
       && !HONOR_SIGNED_ZEROS (TYPE_MODE (type)))))
/* ???  To be continued.  Match up with actual simplifications!  */
/* ???  Unfortunately combining the predicate definition with
   the actual simplification isn't possible.  Would be a special-case
   for negate_expr_p anyway.
     (simplify
       (negate (match negate_expr_p (....))
   anyone?  */


/* tree-ssa/ifc-pr44710.c requires a < b ? c : d to fold to 1.
   ???  probably runs into issue of recursive folding of a < b op0.  */
/* tree-ssa/ssa-ccp-16.c wants to fold "hello"[i_2] to 0
   (fold_const_aggregate_ref_1).  */
/* tree-ssa/ssa-ccp-19.c wants to fold &a1_3->i to &MEM[(void *)&a]
   (get_addr_base_and_unit_offset_1). */
/* tree-ssa/ssa-ccp-22.c wants to fold b_2(D) <= t_1 to 1.
   We are missing compare constant folding to type boundaries.  */

/* The following is simplification done by gimple_fold_stmt_to_constant_1
   to aid propagation engines, producing is_gimple_min_invariants from
   invariant_addr + cst.  It may not be generally wanted
   (builtin-object-size) and thus may want to be restricted to 'simple'
   forms like &mem-ref or &decl.  */
/* Disable for GENERIC, this causes endless recursions of addr-expr
   expansion which folds a POINTER_PLUS_EXPR and doesn't expect
   an ADDR_EXPR in return.  */
#if GIMPLE
(simplify
  (pointer_plus (addr@2 @0) INTEGER_CST@1)
  (if (is_gimple_min_invariant (@2))
  {
    HOST_WIDE_INT off;
    tree base = get_addr_base_and_unit_offset (@0, &off);
    off += tree_to_uhwi (@1);
    /* Now with that we should be able to simply write
       (addr (mem_ref (addr @base) (plus @off @1)))  */
    build1 (ADDR_EXPR, type,
            build2 (MEM_REF, TREE_TYPE (TREE_TYPE (@2)),
	    	    build_fold_addr_expr (base),
	            build_int_cst (ptr_type_node, off)));
  }))
#endif



/* Patterns required to avoid SCCVN testsuite regressions.  */

/* (x >> 31) & 1 -> (x >> 31).  Folding in fold-const is more
   complicated here, it does
     Fold (X << C1) & C2 into (X << C1) & (C2 | ((1 << C1) - 1))
     (X >> C1) & C2 into (X >> C1) & (C2 | ~((type) -1 >> C1))
     if the new mask might be further optimized.  */
(simplify
  (bit_and (rshift@0 @1 INTEGER_CST@2) integer_onep)
  (if (compare_tree_int (@2, TYPE_PRECISION (TREE_TYPE (@1)) - 1) == 0)
   @0))

/* COMPLEX_EXPR and REALPART/IMAGPART_EXPR cancellations.  */
(simplify
  (complex (realpart @0) (imagpart @0))
  @0)
(simplify
  (realpart (complex @0 @1))
  @0)
(simplify
  (imagpart (complex @0 @1))
  @1)

/* One unary pattern.  */

/* fold_negate_exprs convert - (~A) to A + 1.  */
(simplify
  (negate (bit_not @0))
  (if (INTEGRAL_TYPE_P (type))
   (plus @0 { build_int_cst (TREE_TYPE (@0), 1); } )))

/* One ternary pattern.  */

/* Due to COND_EXPRs weirdness in GIMPLE the following won't work
   without some hacks in the code generator.  */
(simplify
  (cond (bit_not @0) @1 @2)
  (cond @0 @2 @1))

/* match-and-simplify handles constant folding so we
   can just do the decomposition here.  */
(simplify
  (fma INTEGER_CST@0 INTEGER_CST@1 @3)
  (plus (mult @0 @1) @3))

/* abs (abs (x)) -> abs (x) */
(simplify
  (abs (abs @0))
  (abs @0))



#include "match-plusminus.pd"
#include "match-bitwise.pd"
#include "match-rotate.pd"
#include "match-builtin.pd"
#include "match-comparison.pd"
#include "match-conversions.pd"

/* ????s

   We cannot reasonably match vector CONSTRUCTORs or vector constants
   without using special predicates.  Nor can we reasonably generate
   variable-length stuff with pattern expressions.

 */
